{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d4b23-8a44-46ac-ba0c-10d33955c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "from sklearn import linear_model    # Herramientas de modelos lineales\n",
    "from sklearn.metrics import mean_squared_error, r2_score    # Medidas de desempeño\n",
    "from sklearn.preprocessing import PolynomialFeatures    # Herramientas de polinomios\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "from formulaic import Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a860ad52-6e0b-407c-a279-358e06dd4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si necesitan instalar algún paquete\n",
    "#!pip install gapminder\n",
    "#!pip install formulaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cf193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si necesitan cambiar de directorio de trabajo\n",
    "#import os\n",
    "#print(pwd)\n",
    "#os.chdir('./notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b965805",
   "metadata": {},
   "source": [
    "Retomamos la última parte del notebook de la clase anterior\n",
    "\n",
    "# Interacciones entre variables y la paradoja de Simpson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0defec",
   "metadata": {},
   "source": [
    "Queremos estudiar la relación entre la longitud y la profundidad del pico de los pingüinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")  # Eliminamos las filas con datos faltantes\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d775e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que hay datos faltanes.\n",
    "# Eliminamos las filas con datos faltantes\n",
    "penguins = penguins.dropna()  \n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82823219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos un modelo lineal y calculamos el coeficiente de correlación R^2\n",
    "y, X = (\n",
    "    Formula('???')\n",
    "    .get_model_matrix(penguins)\n",
    ")\n",
    "display(X.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo.fit(X, y)   # Realizamos el ajuste\n",
    "print(\"Coeficientes:\", modelo.coef_)\n",
    "\n",
    "y_pred = modelo.predict(X)\n",
    "# Calculando el R^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('R^2: ', r2)\n",
    "\n",
    "# Calculando el ECM\n",
    "ecm = mean_squared_error(y, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ff005d",
   "metadata": {},
   "source": [
    "Si analizamos rápidamente estos resultados diríamos que no hay relación entre el largo y la produndidad... (o que hay correlación negativa porque la pendiente es negativa). Resulta un poco extraño..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee31575",
   "metadata": {},
   "source": [
    "¿Cómo podemos analizar mejor qué está pasando?\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdfe28",
   "metadata": {},
   "source": [
    "Realicemos un gráfico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4617e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data = penguins, x = \"bill_length_mm\", y = \"bill_depth_mm\")\n",
    "    .add(so.Dot())\n",
    "    .add(so.Line(), so.PolyFit(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5dc8c",
   "metadata": {},
   "source": [
    "El gráfico confirma la correlación negativa, pero notan algo raro? Tal vez hay algo que no estamos teniendo en cuenta?\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb9535",
   "metadata": {},
   "source": [
    "Repetimos el gráfico coloreando los puntos según la especie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data = penguins, x = \"bill_depth_mm\", y = \"bill_length_mm\", color = \"species\")\n",
    "    .add(so.Dot())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ac09e",
   "metadata": {},
   "source": [
    "En este gráfico por especie vemos dentro de cada especie puede haber correlación. Verificamos agregando los ajustes por especie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50227811",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(data = penguins, x = \"bill_depth_mm\", y = \"bill_length_mm\", color = \"species\")\n",
    "    .add(so.Dot())\n",
    "    .add(so.Line(), so.PolyFit(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca560b0",
   "metadata": {},
   "source": [
    "Ahora las rectas tienen pendiente positiva! Al considerar todas las especies al mismo tiempo, no podíamos ver esta correlación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3e9d4",
   "metadata": {},
   "source": [
    "## La paradoja de Simpson\n",
    "La paradoja de Simpson es un fenómeno estadístico en el cual una relación entre variables aparece, desaparece o se revierte al dividir a la población en subpoblaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024b0a9",
   "metadata": {},
   "source": [
    "**Ejemplo.** Veamos otro ejemplo simulado.\n",
    "Generamos dos poblaciones distribuidas aleatoriamente alrededor de dos centros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a060e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "centers = [[2, 2], [-2, -2]]\n",
    "X, labels_true = make_blobs(\n",
    "    n_samples=750, centers=centers, cluster_std=0.4, random_state=0)\n",
    "x = X[:,0]\n",
    "y = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(x = x, y = y)\n",
    "    .add(so.Dot(), color = labels_true)\n",
    "    .add(so.Line(), so.PolyFit(1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6435d",
   "metadata": {},
   "source": [
    "En este ejemplo, podríamos decir que hay correlación entre la variable $x$ y la variable $y$?\n",
    "\n",
    "Calculemos el R^2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression()    # Inicializamos un modelo de Regresion Lineal\n",
    "modelo.fit(pd.DataFrame(x), y)   # Realiza\n",
    "\n",
    "print(\"Coeficientes:\", modelo.coef_)\n",
    "\n",
    "# Medidas de bondad\n",
    "\n",
    "y_pred = modelo.predict(pd.DataFrame(X[:,0]))\n",
    "\n",
    "# Calculando el R^2\n",
    "r2 = r2_score(X[:,1], y_pred)\n",
    "print('R^2: ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85091992",
   "metadata": {},
   "source": [
    "Los datos parecen altamente correlacionados. Pero si separamos por grupo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f197a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    so.Plot(x = x, y = y)\n",
    "    .add(so.Dot(), color = labels_true)\n",
    "    .add(so.Line(), so.PolyFit(1), group = labels_true)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4536b851",
   "metadata": {},
   "source": [
    "Vemos en el gráfico que la pendiente ahora pasa a ser casi 0.\n",
    "\n",
    "¿Cómo podemos construir nosotros estos modelos y calcular los coeficientes y el R^2?\n",
    "\n",
    "Recordemos las operaciones que nos permite hacer Formulaic.\n",
    "\n",
    "| Operador | Ejemplo          | Función                                                                                           |\n",
    "|:---------|:-----------------|:---------------------------------------------------------------------------------------------------|\n",
    "| ~        | y ~ x            | Separa la variable (y) respuesta a la izquierda, de el/los predictor/es a la derecha (x).       |\n",
    "| +        | y ~ x + z        | Adiciona (suma) términos al modelo.                                                              |\n",
    "| :        | y ~ x : z        | Interacción entre términos. y es lineal en x ⋅ z.                                                |\n",
    "| *        | y ~ x * z        | Combina adición e interacción entre términos. y ~ x * z es equivalente a y ~ x + z + x : z       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = Formula(\"bill_length_mm ~ ???\").get_model_matrix(penguins)\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd39088",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo.fit(X, y)   # Realiza\n",
    "print(\"Coeficientes:\", modelo.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd892530",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cuáles coeficientes nos indican las pendientes de las rectas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c29b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el R^2\n",
    "y_pred = modelo.predict(X)\n",
    "\n",
    "# Calculando el R^2\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('R^2: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los últimos tres números son las pendientes de las rectas.\n",
    "# Cómo podemos graficar este modelo?\n",
    "\n",
    "y_pred = modelo.predict(X)\n",
    "\n",
    "(\n",
    "    so.Plot(data = penguins, x = \"bill_depth_mm\", y = \"bill_length_mm\", color = \"species\")\n",
    "    .add(so.Dot())\n",
    "    .add(so.Line(), ???)  # Otro milagro!! No le tenía ninguna fe a esto :)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28e245",
   "metadata": {},
   "source": [
    "**Ejercicio.** Realizar ahora un modelo donde todas las rectas tengan la misma pendiente y solo cambie el intercept según la especie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521bd69",
   "metadata": {},
   "source": [
    "# Validación cruzada\n",
    "Queremos estimar los costos de salud que tendrá un cliente de una prepaga en función de algunas variables de la persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salud = pd.read_csv('../data/insurance.csv')\n",
    "df_salud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43257c",
   "metadata": {},
   "source": [
    "La variable respuesta es `charges` y el resto son variables explicativas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15501c5",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cuáles son variables numércias? ¿Cuáles son categóricas? Las variables categóricas son: ¿binarias, nominales, ordinales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f536e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21c102",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Cuántas categorías tiene la variable `region`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ddb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otro comando útil para analizar las variables numéricas\n",
    "df_salud.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d40009",
   "metadata": {},
   "source": [
    "Por ejemplo, en la variable `charges` vemos que el promedio es 13270, y el máximo es 63770. Esto podría indica la presencia de outliers, que dificultan el modelo. ¿Cómo podemos visualizar los outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811df3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10852032",
   "metadata": {},
   "source": [
    "Por el momento dejamos los outliers, veremos más adelante pasos para limpieza de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3695b60",
   "metadata": {},
   "source": [
    "## Nivel 1: entrenamos y testeamos el modelo usando todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec42f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = (\n",
    "    Formula('charges ~ age + sex + bmi + children + smoker + region')\n",
    "    .get_model_matrix(df_salud)\n",
    ")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e355f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver la correlación entre las distintas variables (corresponde al R de un modelo lineal y=ax+b)\n",
    "pd.concat([X,y], axis = 1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fe541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "modelo = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo.fit(X, y)   # Realiza\n",
    "print(\"Coeficientes:\", modelo.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe13c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = modelo.predict(X)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9ca04",
   "metadata": {},
   "source": [
    "## Nivel 2: separamos en entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31766fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa91a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "modelo = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo.fit(X_train, y_train)   # Realiza\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73650a96",
   "metadata": {},
   "source": [
    "**Pregunta:** Con la semilla aleatoria 42 bajó el ECM. Si cambiamos la semilla por ejemplo a 4?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70954ce",
   "metadata": {},
   "source": [
    "## Nivel 3: separamos en entrenamiento, validación y testeo\n",
    "#### Paso 1: separamos en entrenamiento y testeo el dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b206f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_salud, test_size=0.2, random_state=42)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de88abe",
   "metadata": {},
   "source": [
    "Podemos también primero aplicar transformar las variables y después separar en entrenamiento y testeo, pero es preferible separar al principio el conjunto de testeo, para evitar usar en el entrenamiento datos del conjunto de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c07be",
   "metadata": {},
   "source": [
    "#### Paso 2A: definimos un primer modelo y separamos el dataset df_train en entrenamiento y validación para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7531bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula1 = 'charges ~ age + sex + bmi + children + smoker + region'\n",
    "y1, X1 = (\n",
    "    Formula(formula1)\n",
    "    .get_model_matrix(df_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87311640",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo1 = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo1.fit(X_train, y_train)   # Realiza\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo1.predict(X_val)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y_val, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae38a9",
   "metadata": {},
   "source": [
    "#### Paso 2B: definimos otro modelo y repetimos el paso 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula2 = 'charges ~ age + bmi + children + smoker'\n",
    "y2, X2 = (\n",
    "    Formula(formula2)\n",
    "    .get_model_matrix(df_train)\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb405fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2 = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "modelo2.fit(X_train, y_train)   # Realiza\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo2.predict(X_val)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y_val, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6e81a",
   "metadata": {},
   "source": [
    "#### Paso 3: de los modelos probados, nos quedamos con el de menor RECM. \n",
    "Analizamos como funciona el modelo en el conjunto de validación.\n",
    "\n",
    "Para esto, entrenamos el modelo ganador utilizando TODOS los datos de entrenamiento (el modelo es la fórmula, no los coeficientes).\n",
    "\n",
    "**Recordar:** mientras mas datos usamos para entrenar, mejor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c330f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos nuestro modelo ganador en TODO el conjunto de entrenamiento. \n",
    "modelo1.fit(X1, y1)\n",
    "\n",
    "# Realizamos las mismas transformaciones en el conjunto de testeo\n",
    "y_test, X_test = (\n",
    "    Formula(formula1)\n",
    "    .get_model_matrix(df_test)\n",
    ")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo1.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2619cd",
   "metadata": {},
   "source": [
    "## Nivel 4: separamos en entrenamiento y testeo, y hacemos validación cruzada en el conjunto de entrenamiento.\n",
    "### Paso 1: separamos en entrenamiento y testeo el dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La misma separación del Nivel 3\n",
    "df_train, df_test = train_test_split(df_salud, test_size=0.2, random_state=42)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b47a2b6",
   "metadata": {},
   "source": [
    "#### Paso 2A: definimos un primer modelo y lo ajustamos por validación cruzada en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula1 = 'charges ~ age + sex + bmi + children + smoker + region'\n",
    "y1, X1 = (\n",
    "    Formula(formula1)\n",
    "    .get_model_matrix(df_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379154ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los subconjuntos para la validación cruzada.\n",
    "# Utilizamos KFold de sklearn\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebe629",
   "metadata": {},
   "source": [
    "## Generadores e iteradores perezosos en Python\n",
    "Nos detenemos un momento para entender qué nos devuelve KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto solo nos muestra las opciones que utilizamos\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La forma de utilizado es a través del método split\n",
    "pliegos = cv.split(X1)\n",
    "pliegos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960642ef",
   "metadata": {},
   "source": [
    "`split` nos devuelve un \"generador\", esto es un **iterador perezoso** (lazy iterator).\n",
    "\n",
    "Los iteradores perezosos son objetos que se pueden recorrer como una lista. \n",
    "\n",
    "Sin embargo, a diferencia de las listas, los iteradores perezosos no almacenan su contenido en la memoria, lo van generando a medida que lo necesitamos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3179dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos acceder a los elementos a través de la función next\n",
    "next(pliegos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pero lo mas común es utilizarlos en un ciclo:\n",
    "pliegos = cv.split(X1)\n",
    "for train_index, test_index in pliegos:\n",
    "    print(test_index[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fc776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora no quedo nada, ya generó todo lo que tenía para generar\n",
    "next(pliegos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0228e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acá tampoco hay nada...\n",
    "for train_index, test_index in pliegos:\n",
    "    print(test_index[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ce2f9",
   "metadata": {},
   "source": [
    "#### Volvemos al Paso 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5169a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "for train_index, val_index in cv.split(X1):\n",
    "    X_train, X_val, y_train, y_val = X1.iloc[train_index], X1.iloc[val_index], y1.iloc[train_index], y1.iloc[val_index]\n",
    "    \n",
    "    # Acá tenemos que hacer el ajuste y la predicción para cada pliego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53c0c8",
   "metadata": {},
   "source": [
    "Agregamos el codigo para ajuste y predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424882b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo1 = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "rmse1 = np.zeros(cv.get_n_splits())  # Vamos a guardar el error en cada pliego\n",
    "\n",
    "ind = 0\n",
    "\n",
    "# Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "for train_index, test_index in cv.split(X1):\n",
    "    X_train, X_val, y_train, y_val = X1.iloc[train_index], X1.iloc[val_index], y1.iloc[train_index], y1.iloc[val_index]\n",
    "    modelo1.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = modelo1.predict(X_val)\n",
    "    rmse1[ind] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc9ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9869fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse1.mean())  # Este es el valor que queremos minimizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb16a43",
   "metadata": {},
   "source": [
    "#### Paso 2B: definimos otro modelo y repetimos el paso 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula2 = 'charges ~ age + bmi + children + region + smoker'\n",
    "y2, X2 = (\n",
    "    Formula(formula2)\n",
    "    .get_model_matrix(df_train)\n",
    ")\n",
    "\n",
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)  # No es necesario definirlo nuevamente, solo para recordar que era.\n",
    "\n",
    "modelo2 = linear_model.LinearRegression(fit_intercept = False)    # Inicializamos un modelo de Regresion Lineal sin intercept\n",
    "rmse2 = np.zeros(cv.get_n_splits())  # Vamos a guardar el error en cada pliego\n",
    "\n",
    "ind = 0\n",
    "\n",
    "# Para seleccionar algunas filas dados los índices, utilizamos iloc (lo vimos en la clase 2)\n",
    "for train_index, test_index in cv.split(X2):\n",
    "    X_train, X_val, y_train, y_val = X2.iloc[train_index], X2.iloc[val_index], y2.iloc[train_index], y2.iloc[val_index]\n",
    "    modelo2.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = modelo2.predict(X_val)\n",
    "    rmse2[ind] = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse2)\n",
    "print(rmse2.mean())  # Este es el valor que queremos minimizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c095b4",
   "metadata": {},
   "source": [
    "#### Paso 3: de los modelos probados, nos quedamos con el de menor RECM. \n",
    "Analizamos como funciona el modelo en el conjunto de validación.\n",
    "\n",
    "Copiamos el mismo código del paso 3 del nivel 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaff57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos nuestro modelo ganador en TODO el conjunto de entrenamiento. \n",
    "modelo2.fit(X2, y2)\n",
    "\n",
    "# Realizamos las mismas transformaciones en el conjunto de testeo\n",
    "y_test, X_test = (\n",
    "    Formula(formula2)\n",
    "    .get_model_matrix(df_test)\n",
    ")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo2.predict(X_test)\n",
    "\n",
    "# Bondad del ajuste\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R^2: ', r2)\n",
    "ecm = mean_squared_error(y_test, y_pred)\n",
    "print('Raiz cuadarada del ECM: ', np.sqrt(ecm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829ddb96",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Repetir los ejercicios de la prática 5 utilizando validación cruzada para seleccionar el mejor modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eed2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
