\documentclass[a4paper,11pt]{article}
\usepackage{amssymb, enumitem}
\setlist[enumerate,1]{label={\bfseries\arabic*.},ref={\bfseries{Ejercicio \arabic*}}}
\setlist[enumerate,2]{label={\bfseries(\alph*)},ref={\bfseries(\alph*)}}


\parindent 0cm
\usepackage{amssymb,amsmath,amsthm,latexsym,epsfig,euscript,multicol}
\usepackage{graphbox}

\usepackage[utf8x]{inputenc}
\usepackage{listings,xcolor,bm}


\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
  backgroundcolor=\color{white},   % choose the background color; you must add
  basicstyle=\ttfamily,      % the size of the fonts that are used for the code
  breakatwhitespace=true,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  firstnumber=1,                % start line enumeration with line 1000
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Python,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=none,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=5,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=4,	                   % sets default tabsize to 2 spaces
  title=\lstname,                  % show the filename of files included with \lstinputlisting; also try caption instead of title
  belowskip=0em
}
% Caracteres especiales
\def\A{\mathbb{A}}
\def\C{\mathbb{C}}
\def \N{\mathbb{N}}
\def \P{\mathbb{P}}
\def \Q{\mathbb{Q}}
\def \R{\mathbb{R}}
\def \Z{\mathbb{Z}}
\def \sen{\textrm{sen}}

\def\Np{$\N$}
\def\Zp{$\Z$}
\def\Qp{$\Q$}
\def\Rp{$\R$}
\def\Cp{$\C$}

\def\bb{\bm{b}}
\def\bu{\bm{u}}
\def\bv{\bm{v}}
\def\bx{\bm{x}}
\def\bA{\bm{A}}
\def\bB{\bm{B}}
\def\bD{\bm{D}}
\def\bE{\bm{E}}
\def\bM{\bm{M}}
\def\bT{\bm{T}}


\def\K{\textrm{K}}
\def\V{\textrm{V}}
\def\S{\textrm{S}}

\def\degres{$^\circ$}

\newcount\todno
\def\no{\global\advance\todno by 1 \the\todno}

\topmargin-2cm \vsize 29.5cm \hsize 21cm
\setlength{\textwidth}{16.75cm}\setlength{\textheight}{23.5cm}
\setlength{\oddsidemargin}{0.0cm}
\setlength{\evensidemargin}{0.0cm}


\theoremstyle{definition}
\newtheorem{ejer}{Ejercicio}
\newcommand{\bej}{\begin{ejer}}
\newcommand{\fej}{\end{ejer}}

\begin{document}

\centerline{{\small Universidad de Buenos Aires - Facultad de Ciencias Exactas y Naturales - Ciencias de Datos}}

\vskip 0.2cm

\hrule

\vskip 0.2cm

 \centerline{{\bf\Large{\sc Laboratorio de Datos}}}

 \vskip 0.2cm

 \centerline{\ttfamily Primer Cuatrimestre 2024}

\vskip 0.2cm

 \hrule

 \bigskip
 \centerline{\bf Práctica N$^\circ$ 5: Modelo lineal multivariado. Entrenamiento y testeo.}
 \bigskip


% \textbf{\large Visualizaci\'on}

\begin{enumerate}

\item \label{ejer:grado3} Queremos estudiar la relación entre la longitud de la aleta de un ping\"uino y el peso del ping\"uino. Como en una esfera, el peso es proporcional a la longitud del radio elevada al cubo, podemos conjeturar que un polinomio de grado 3 es apropiado para ajustar el peso en función de la longitud de la aleta. Queremos verificar si nuestra conjetura tiene sustento en los datos.
\begin{enumerate}
\item \label{item:nan} \textbf{Datos faltantes.} Ejecutar el siguiente c\'odigo y observar si hay filas con datos faltantes (NaN).
\begin{lstlisting}
penguins = sns.load_dataset("penguins")
penguins.head()
\end{lstlisting}

Para hacerlo en forma más sistemática (en lugar de mirar solo algunas filas) podes usar el siguiente código
\begin{lstlisting}
penguins.isnull().values.any()
\end{lstlisting}

Para eliminar las filas con valores faltantes aplicamos al DataFrame el método \lstinline{dropna()}. Eliminar las filas con datos faltantes del DataFrame de ping\"uinos y verificar que el DataFrame resultante no contiene valores faltantes.

\item \textbf{Conjuntos de entrenamiento y testeo.} Dividir el dataset resultante  en un grupo de entrenamiento y uno de testeo (80\% - 20\%).
Hacerlo de las siguientes dos formas distintas:

\vspace{.5cm}

A. Utilizando un array de Numpy para filtrar:
\begin{enumerate}
\item Crear un array de Numpy booleano de longitud igual a la cantidad de filas del DataFrame que tome el valor True en el primer $80\%$ de las coordenadas y False en el restante $20\%$.
\item Si se quiere seleccionar una muestra al azar, se puede utilizar \lstinline{numpy.random.shuffle} para ``mezclar'' el vector.
\item Utilizar el vector generado para filtrar el Dataframe.
\end{enumerate}

Siguiendo esos pasos, completar el siguiente código:
\begin{lstlisting}
train_ind = np.full(???, False)
train_ind[0:???] = True
np.random.shuffle(train_ind)  # Lo guarda en el mismo vector.
penguins_train = penguins[???]
penguins_test = penguins[???]
\end{lstlisting}

B. Utilizando la función \lstinline{train_test_split} de \lstinline{sklearn}:
\begin{lstlisting}
from sklearn.model_selection import train_test_split
penguins_train, penguins_test = train_test_split(penguins, test_size=0.2, random_state=42)
\end{lstlisting}

En este codigo, \lstinline{random_state} se conoce también como semilla aleatoria. Si corremos varias veces el código con el mismo número, obtendremos siempre la misma muestra. Esto permite que el experimento sea reproducible. Si modificamos el número (o no lo indicamos), obtendremos distitnas muestras aleatorias.

\vspace{.5cm}

Podemos también separar primero las variables explicativas y variable respuesta:

\begin{lstlisting}
from sklearn.model_selection import train_test_split
X = ???
y = ???
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
\end{lstlisting}


\item Crear y ajustar 3 modelos utilizando polinomios de grados 1, 2 y 3.
\item Calcular para cada uno el error predicción en el grupo de entrenamiento y en el grupo de test.
\item ¿Cuál modelo tiene el menor error (ECM) en el ajuste? ¿Cuál el menor error (ECM) de predicción?
\item En base a los resultados obtenidos, ¿cu\'al de los tres modelos utilizaría?
\end{enumerate}

\item En el archivo \lstinline{50_startups.csv} tenemos los siguientes datos de 50 compa\~n\'ias: gastos en investigación y desarrollo, gastos administrativos, gastos en marketing y ganancias. Queremos estimar las ganancias a partir de los gastos en las distintas áreas.
\begin{enumerate}
\item Leer el archivo, y realizar un gráfico de dispersión para cada par de variables. Se pueden generar todos los gráficos automáticamente con el \lstinline{pairplot}.
\begin{lstlisting}
startups = pd.read_csv(???)
sns.pairplot(
    data=startups, aspect = .8)
\end{lstlisting}

En base a estos gr\'aficos, si quisiéramos predecir la ganancia mediante un modelo lineal utilizando una sola variable predictora, ¿cu\'al variable utilizar\'ia? Diseñar un experimento para verificar su respuesta.
\item En este ejemplo, ¿considera que un modelo lineal multivariado ayudar\'ia a predecir mejor la ganancia que el modelo lineal univariado del ítem anterior? Realizar un experimento para verificar su respuesta.
\end{enumerate}

\item En el \ref{ejer:grado3} no tuvimos en cuenta el sexo del ping\"uino para predecir el peso, y puede ser una variable importante. Se quiere predecir ahora el peso de un ping\"uino usando como variables predictoras el largo de la aleta y el sexo del ping\"uino (utilizar el DataFrame sin datos faltantes, como vimos en el \ref{ejer:grado3} \ref{item:nan}).
\begin{enumerate}
\item ¿Cu\'ales son todos los valores que toma la variable ``sex''? ¿Qu\'e tipo de variable es: numérica o categórica, ordinal o nominal? ¿Es una variable binaria?

\item Escribir (en lápiz y papel) la ecuación de un modelo lineal para este caso. ¿Qué unidades tienen las variables y cómo se codifica la variable “sexo del pinguino”?

\item \textbf{Codificación de variables binarias.} Si utilizamos \lstinline{Formulaic} para generar la matriz de datos e incluimos la variable sexo en el modelo, automáticamente va a  crear una columna con el sexo codificado con 0's y 1's.

    Alternativamente, podemos utilizar el siguiente c\'odigo:
\begin{lstlisting}
from sklearn.preprocessing import OrdinalEncoder
encoder = OrdinalEncoder()
sex01 = encoder.fit_transform(penguins[["sex"]])
penguins["sex01"] = sex01
\end{lstlisting}

\item Ajustar el modelo usando todos los datos disponibles. Reportar los coeficientes encontrados y calcular el error de predicción (ECM). ?`Considera que agregar la variable ``sex'' mejoró el modelo?
\item Realizar una visualización apropiada para ver de los datos junto con las predicciones del modelo.
\item Dos ping\"uinos que tienen igual largo de aleta, uno macho y otro hembra, ¿qué diferencia de peso predice el modelo que tendrán?
\end{enumerate}

\item Ahora se quiere predecir el peso de un pinguino usando como variables predictoras el largo de la aleta y la especie del ping\"uino.
\begin{enumerate}
\item Trabajamos con la base de ping\"uinos sin datos faltantes. ¿Cu\'ales son todos los valores que toma la variable ``species''? ¿Qu\'e tipo de variable es: numérica o categórica, ordinal o nominal? ¿Es una variable binaria?
\item Escribir (en lápiz y papel) la ecuación de un modelo lineal para este caso. ¿Cómo se codifica la variable “especie”?
\item Explicar qué diferencia tiene este modelo respecto al propuesto en el ejercicio 1.
\item \textbf{Codificación de variables categóricas.}  Si utilizamos \lstinline{Formulaic} para generar la matriz de datos e incluimos variables categóricas, automáticamente va a crear las columnas indicadoras con 0's y 1's necesarias (variables dummies).

    Alternativamente podemos usar el siguiente código que utiliza la función \lstinline{OneHotEncoder}:
\begin{lstlisting}
from sklearn.preprocessing import OneHotEncoder
penguins = sns.load_dataset("penguins").dropna()
encoderOHE = OneHotEncoder(sparse_output = False)
species3 = encoderOHE.fit_transform(penguins[["species"]])
species3_df = pd.DataFrame(species3, columns=encoderOHE.get_feature_names_out(), index=penguins.index)
penguins3 = pd.concat([penguins, species3_df], axis = 1)
penguins3.head()
\end{lstlisting}

Si utilizan este código, verifiquen que los tama\~nos de \lstinline{species3} y \lstinline{penguins3} sean los esperados, y que el DataFrame resultante no tenga datos faltantes (como el DataFrame original no tiene faltantes, este tampoco debería tenerlos, pero nunca está mal verificarlo).

\item Ajustar el modelo usando todos los datos disponibles. Reportar los coeficientes encontrados y calcular el error de predicción.
\item Realizar una visualización apropiada para ver de los datos junto con las predicciones del modelo.
\end{enumerate}

\item En este ejercicio trabajaremos con el dataset de inmuebles (\verb|inmuebles.csv|). El objetivo de este ejercicio es comparar tres modelos lineales para predecir el precio de un inmueble:
\[
\begin{array}{rl}
    \text{Modelo 1:} &  precio \sim superficie \\
    \text{Modelo 2:} &  precio \sim superficie + zona \\
    \text{Modelo 3:} &  \text{un modelo propuesto por usted}
\end{array}
\]
Como medida de comparación utilizaremos la raíz cuadrada del ECM, que notaremos RECM. En cada ítem, indicar qué modelo tiene el mejor desempeño.

\begin{enumerate}
    \item \textit{Nivel 1}. Entrenar cada modelo sobre la totalidad de los datos disponibles. Graficar, en una misma figura, los datos y las predicciones del modelo 2 y del modelo 3. Las predicciones deben estar señaladas en la leyenda (recuerde el uso del argumento \verb|label|) y las lineas del modelo 3 deben estar punteadas (investigue agregar \verb|linestyle='--'| donde corresponda). Puede adaptar el siguiente c\'odigo:
\begin{lstlisting}
(
    so.Plot(data=data, x='superficie', y='precio')
    .add(so.Dot(), color='zona')
    .add(so.Line(), y=modelo.predict(X).flatten(), color='zona')
)
\end{lstlisting}
\item \textit{Nivel 2}. Separar los datos en conjuntos de entrenamiento (\textit{train}) y prueba (\textit{test}). Entrenar cada modelo sobre el \underline{mismo} conjunto de entrenamiento y comparar su desempeño sobre el conjunto de prueba.
\item \textit{Nivel 3}. Separar los datos en dos conjuntos: entrenamiento y testeo. Luego, dividir el conjunto de entrenamiento en dos conjuntos: entrenamiento y validaci\'on. Entrenar cada modelo sobre el conjunto de entrenamiento y comparar su desempeño en el conjunto de validación. Elija el que usted considere el más apropiado, entrénelo sobre la unión de los datos de testeo y validación  y calcule la RECM y el $R^2$ sobre el conjunto de testeo.
\item \textit{Nivel 4 - $k$-Fold Cross-Validation}. Aplicar validaci\'on cruzada en $k$ pliegos con $k=6$. Para esto, separar el conjunto de datos en entrenamiento y testeo. Aplicar la t\'ecnica de $k$-Fold CV para cada modelo con el conjunto de testeo. Elegir el modelo con menor promedio de RECM y calcular la RECM y el $R^2$ sobre el conjunto de testeo.
\end{enumerate}

\item \textbf{Regresión Ridge.} Queremos estimar los gastos en tarjeta de crédito de un conjunto de clientes a partir de información de los clientes. Utilizamos el dataset \lstinline{credit.csv}.
    
\begin{enumerate}
\item Cargar el dataset con Pandas. En regresión Ridge variables en distintas escalas pueden afectar el modelo, por lo tanto es conveniente llevar todas las variables a una misma escala, por ejemplo, al intervalo $[0, 1]$. Para eso podemos utilizar el siguiente código.

\begin{lstlisting}
df = pd.read_csv("../data/Credit.csv")
columns = ['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education']
df[columns] /= df[columns].max()
\end{lstlisting}

La última divide los valores en las columnas indicadas por el máximo de la columna. Veremos más sobre procesamiento previo de datos en la próxima práctica.

\item Separar los datos en entrenamiento y testeo, ajustar un modelo lineal en los datos de entranamiento y calcular el RMSE (raíz del error cuadrático medio) en los datos datos de testeo.
\item Obtener por validación cruzada en los datos de entrenamiento el valor óptimo para el hiperparámetro $\alpha$ de regresión Ridge. Utilizar como vector de búsqueda \lstinline{alphas = np.array([0.001, 0.005, 0.01, 0.02, 0.1, 0.5, 1])}.
\item Con el valor obtenido, ajustar el modelo de regresión Ridge a los datos de entreanamiento.
\item Calcular el RMSE (raíz del error cuadrático medio) en los datos datos de testeo. 
\item ¿En cuál de los dos modelos obtuvo mejor resultados?
\end{enumerate}

\end{enumerate}

\end{document}

