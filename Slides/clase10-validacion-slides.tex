\documentclass[aspectratio=169,12pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-nodecimaldot]{babel}
%\usepackage{icomma} % Use dot as decimal separator
\usepackage{booktabs} % For better-looking tables
\usepackage{wrapfig}
%\usepackage{siunitx}

\usepackage{multicol}
\usepackage{mathtools}

\usepackage[normalem]{ulem}

\pagestyle{empty}

\usepackage{pgf,tikz}
\usepackage{pgfplots}
\usetikzlibrary{matrix}
\usetikzlibrary{arrows}

%\usepackage{wrapfig}
\mode<presentation>
\usefonttheme{professionalfonts}
\usetheme{Darmstadt}
\usecolortheme{orchid}
\useoutertheme{default}
\setbeamertemplate{headline}{}

\renewcommand{\baselinestretch}{1.1}

%gets rid of bottom navigation bars
\setbeamertemplate{footline}[page number]

%gets rid of navigation symbols
\setbeamertemplate{navigation symbols}{}

%\frameframe{none} % No default frame

%\setlength{\framewidth}{8.7in} \setlength{\frameheight}{7.2in}

\parindent 0pt
\setlength{\parskip} {1ex plus 0.5ex minus 0.2ex}


%\usepackage[bbgreekl]{mathbbol}
\usepackage{amsfonts}

%\DeclareSymbolFontAlphabet{\mathbb}{AMSb}
%\DeclareSymbolFontAlphabet{\mathbbl}{bbold}

\newcommand{\Sym}{{\mathcal S}}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\trace}{Trace}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}

\usepackage{breqn}
\usepackage{multicol}
\usepackage{colortbl}
\usepackage{lmodern}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{color}
\usepackage{graphicx}
\graphicspath{ {img/} }
\usepackage{hyperref}

\input{epsf}
\title{Introducción}
\author{}

\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\sing}{sing}

\DeclareMathOperator{\chara}{char}
\DeclareMathOperator{\Jacob}{Jacob}
\DeclareMathOperator{\Sing}{Sing}
\newcommand{\fracNoLine}[2]{\genfrac{}{}{}{0pt}{#1}{#2}}

%\beamerdefaultoverlayspecification{<+->}

\usepackage{listings,xcolor,bm}


\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
  backgroundcolor=\color{white},   % choose the background color; you must add
  basicstyle=\small\ttfamily,      % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  firstnumber=1,                % start line enumeration with line 1000
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Python,                 % the language of the code
  morekeywords={*,...},            % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=5,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=4,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\begin{document}

\newtheorem{prop}{Proposici\'on}
\newtheorem{algo}[prop]{Algorithm}
\newtheorem{teor}[prop]{Theorem}
\newtheorem{lema}[prop]{Lemma}
\newtheorem{coro}[prop]{Corollary}
\newtheorem{defi}[prop]{Definition}

\newcommand{\ideal}[1]{{\left\langle{#1}\right\rangle}}
\newcommand{\demo}{\textbf {Demostraci\'on. }}
\newcommand{\obse}{\textbf {Observaci\'on. }}
\newcommand{\Input}{\textbf {Input: }}
\newcommand{\Output}{\textbf {Output: }}
\newcommand{\Examp}{\textbf {Ejemplo }}
\newcommand{\Examps}{\textbf {Ejemplos }}

\newcommand{\kk}{{\mathbbl k}}
\newcommand{\V}{{\mathbf V}}
\newcommand{\I}{{\mathbf I}}
\newcommand{\PP}{{\tilde P}}
\newcommand{\QQ}{{\tilde Q}}

\newcommand{\F}{{\mathbb F}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\CC}{{\mathbb C}}
\newcommand{\eLL}{{\mathcal L}}



\newcommand{\MinAss}{\textrm {MinAss}}
\newcommand{\Ass}{\textrm {Ass}}
\newcommand{\mcm}{\textrm {mcm}}
\newcommand{\mcd}{\textrm {mcd}}
%\newcommand{\mod}{\textrm { mod }}
\newcommand{\lt}{\textrm {lt}}
\newcommand{\Lt}{\textrm {Lt}}
\newcommand{\lp}{\textrm {lp}}
\newcommand{\lc}{\textrm {lc}}
\newcommand{\lm}{\textrm {lm}}
\newcommand{\barra}{\ /\ }
\newcommand{\multideg}{\textrm {multideg}}

\newcommand{\sep}{\textrm {sep}}
\newcommand{\Syz}{\textrm {Syz}}
\newcommand{\n}{\~n}
\newcommand{\cG}{\textrm {cG}}
\newcommand{\dG}{\textrm {dG}}
\newcommand{\nG}{\textrm {nG}}
\newcommand{\CE}{\textrm {CE}}
\newcommand{\CG}{\textrm {CG}}
\newcommand{\CF}{\textrm {CF}}
\newcommand{\DG}{\textrm {DG}}
\renewcommand{\NG}{\textrm {NG}}

\newcommand{\p}{{\boldsymbol{p}}}
\newcommand{\q}{{\boldsymbol{q}}}

\newcommand{\X}{{\boldsymbol{X}}}
\newcommand{\x}{{\boldsymbol{x}}}
\renewcommand{\u}{{\boldsymbol{u}}}
\renewcommand{\t}{{\boldsymbol{t}}}
\renewcommand{\a}{{\boldsymbol{a}}}
\renewcommand{\b}{{\boldsymbol{b}}}
\renewcommand{\c}{{\boldsymbol{c}}}

%Titulos en espa�ol
%\renewcommand{\chaptername}{Cap\'{\i}tulo}
%\renewcommand{\bibname}{Bibliograf\'{\i}a}

\newcommand{\kring}{\kk[\x]}
\newcommand{\kRing}{\kk[X]}
\newcommand{\qring}{\Q[\x]}

%\renewcommand\itemindent{-10pt}
%\renewcommand{\theenumi}{\arabic{enumi}}
%\renewcommand{\labelenumi}{\Alph{enumi}}

\definecolor{issac}{rgb}{1.00,0.00,0.00}
%------------------------------------------------------------------

\begin{frame}

 \begin{center}

\Large\textbf{Laboratorio de Datos} \\
\large\textbf{Entrenamiento y testeo}
%\vspace{0.5cm}

% \textit{Santiago Laplagne} \\
%slaplagn@dm.uba.ar \\


%\vspace{0.5cm}
%{\small Trabajo en progreso en conjunto con \emph{Jose Capco} (Universit\"at Innsbruck) y \emph{Claus Scheiderer} %(Universit\"at Konstanz).} \\

\vspace{1cm}
Primer Cuatrimestre 2024 \\ Turnos tarde y noche

\vspace{1cm}


 {\small Facultad de Ciencias Exactas y Naturales, UBA}
 \end{center}


\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{?`C\'omo elegir entre distintos modelos?}

Toda tarea de «aprendizaje automático», «machine learning» o «inteligencia artificial»,
consiste en:
\begin{enumerate}
\item Tomar un problema relevante del mundo material.
\item Elegir un modelo matemático que lo represente. El modelo en general va a depender de ciertos parámetros $\beta_1, \dots, \beta_s$.
Por ejemplo en un modelo de regresión lineal, estos parámatros son los coeficientes de cada variable.
\item Definir una forma de medir qu\'e tan bueno es un modelo, en relación a la realidad (vía los datos disponibles).
Esto suele hacerse mediante una \emph{función de pérdida}.
\item $\dots$
\end{enumerate}
\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{?`C\'omo elegir entre distintos modelos?}

\textbf{Función de pérdida:} Si fijamos los parámetros de nuestro modelo $\beta_1, \dots, \beta_s$ y aplicamos el modelo resultante a un conjunto de datos $X$, la función de pérdida mide cuánto ``perdemos'' utilizando el modelo en lugar de los datos reales.
En regresión lineal, la función de pérdida más común es el \emph{error cuadrático medio (MSE)}.

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{?`C\'omo elegir entre distintos modelos?}

Toda tarea de «aprendizaje automático», «machine learning» o «inteligencia artificial»,
consiste en:
\begin{enumerate}
\item Tomar un problema relevante del mundo material.
\item Elegir un modelo matemático que lo represente. El modelo en general va a depender de ciertos parámetros $\beta_1, \dots, \beta_s$.
Por ejemplo en un modelo de regresión lineal, estos parámatros son los coeficientes de cada variable.
\item Definir una una \emph{función de pérdida}.
\item ``Aprender'' los coeficientes $\beta_1, \dots, \beta_s$. Es decir, encontrar valores $\beta_1, \dots, \beta_s$ que minimicen la pérdida.
\end{enumerate}
\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Nivel 0: Entrenar y evaluar sobre todo el conjunto de datos}

Como primer acercamiento, entrenamos nuestros modelos con un conjunto de datos $X$ y evaluamos la perfomance sobre \emph{los mismos datos $X$}.

En este contexto, si un modelo $M_1$ es \emph{más complejo} que un modelo $M_0$ (es decir tiene más variables o parámetros), entonces necesariamente el valor de la función de pérdida será menor o igual.

Ejemplo:
\begin{itemize}
\item $M_0 = \text{gastos mensuales} ~ b_0 + b_1 \text{sueldo} + b_2 \text{cantidad de hijos}$
\item $M_1 = \text{gastos mensuales} ~ b_0 + b_1 \text{sueldo} + b_2 \text{cantidad de hijos} + b_3 \text{altura}$
\end{itemize}

El modelo $M_1$ es m\'as complejo que $M_0$. Podemos ver a $M_0$ como un caso particular de $M_1$ tomando $b_3 = 0$.

El valor mínimo de pérdida de $M_1$ es menor o igual que el valor mínimo de pérdida de $M_0$.


\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{Nivel 1: Entrenar y evaluar sobre todo el conjunto de datos}

Pero esto no nos asegura que el modelo $M_1$ es mejor que $M_0$ (tiene mejor capacidad predictiva).

Que un modelo alcance un error muy pequeño durante el entrenamiento, puede ser tanto por mérito propio del modelo como un síntoma de una excesiva parametrización, que le permite ``interpolar'' o ``memorizar'' los datos.

Si tenemos $n$ observaciones y tomamos un polinomio de grado $n-1$ o un modelo con $n$ variables (independientes), vamos a poder obtener un modelo exacto, la pérdida será 0.

\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Nivel 2: Separar en conjuntos de entrenamiento («train») y prueba («test»)}

Para evitar el \emph{sobreajuste} (overfitting) de los modelos, es habitual dividir el conjunto
de datos en dos partes mutuamente excluyentes (y conjuntamente exhaustivas, ¡nada
se tira!).

Entrenaremos cada modelo con los mismos datos de train para obtener los $\beta$
óptimos, pero seleccionaremos como ``mejor'' a aquel modelo que minimice la pérdida  sobre el conjunto de test.


\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Nivel 3: Split entrenamiento - validación - prueba}

Como antes argumentamos que el modelo que minimiza el error de entrenamiento
puede estar sobreajustándose a los datos, es igualmente posible que aquél que minimiza el error de prueba esté sobreajustándose a los datos de test: al fin y al cabo, así fue como definimos nuestra regla de selección (minimizar el error de prueba).

Para evitar este problema, se suele dividir el conjunto de datos en tres partes: entrenamiento, validación y test:
\begin{enumerate}
\item Entrenamos los modelos minimizando L en Xtrain (los datos de entrenamiento)
\item Seleccionamos el mejor minimizando L en Xval y
\item Evaluamos su performance ``en el mundo real'' con L
\end{enumerate}

\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Nivel 4: Validación Cruzada en $k$ Pliegos (``K-fold CV'')}

En un esquema tripartito «train-val-test», el error de test sólo sirve para reporte, y
achica el tamaño efectivo de la muestra. Más aún, como hay un único conjunto de
test, y todo el proceso está atravesado por ruido estocástico, la selección de modelos
sigue teniendo un fuerte componente de azar.

Si queremos estimar la distribución del error de prueba Ltest de un modelo, necesitaremos de varias repeticiones del experimento. ¿Pero de dónde sacamos los datos para ello?

¡Pues los reutilizamos!

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{Sobreajuste}

En validación cruzada de k pliegos (``k-fold cross-validation''), dividimos primero el conjunto de datos sólo en
train y test. Luego, partimos train en en k partes iguales, que se rotarán el papel de validacion: entrenamos y
evaluamos el modelo $k$ veces, cada vez dejando uno distinto de los $k$ pliegos como val y el resto para train.

\begin{center}
\includegraphics[scale=0.5]{clase10-grid_search_cross_validation.png}
\end{center}


\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{Selección de modelos}

¿Qué estrategias se les ocurren para ver cuál modelo es mejor? \pause

\begin{enumerate}
\item Verificar la fórmula en otros días. \pause
\item Utilizar más días al plantear el sistema de ecuaciones.
\end{enumerate}

\pause

Las dos estretegias son ideas centrales en la construcción de modelos:
\begin{enumerate}
\item Probar el modelo en datos distintos a los que usamos para construir el modelo.
\item Utilizar la mayor cantidad posible de datos para construir el modelo.
\end{enumerate}

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{1. Conjuntos de entrenamiento y testeo}

Separamos nuestro conjunto de datos en dos subconjuntos:
\begin{itemize}
\item \textbf{Conjunto de entrenamiento.} Lo utilizamos para construir el modelo. En un modelo lineal, lo usamos para calcular los coeficientes
    ($c_1, c_2, c_3$).
\item \textbf{Conjunto de testeo.} Lo utilizamos para verificar si el modelo construido ajusta bien a los datos en este conjunto.
\end{itemize}

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{2. Más ecuaciones que variables - Ejemplo de juguete}

Si consideramos el sistema original, tenemos 5 ecuaciones y 3 variables.

\begin{align*}
& \quad YPF \quad \ Santander \quad Nvidia \\
& \quad \quad \downarrow \quad  \quad  \quad  \quad \downarrow  \quad  \quad \quad \quad \downarrow  \\
\text{D\'ia 1} \rightarrow \quad 170262.00	&= 20935	c_1 + 20100 c_2 + 37100.0 c_3 \\
\text{D\'ia 2} \rightarrow \quad 169929.50	&= 21030	c_1 + 20500 c_2 + 36255.0 c_3 \\
\text{D\'ia 3} \rightarrow \quad 171064.00	&= 20770	c_1 + 21700 c_2 + 36000.0 c_3 \\
\text{D\'ia 4} \rightarrow \quad 169637.35	&= 20950	c_1 + 21000 c_2 + 35645.5 c_3 \\
\text{D\'ia 5} \rightarrow \quad 164625.45	&= 20750	c_1 + 20316 c_2 + 33878.5 c_3
\end{align*}

En este ejemplo (de juguete) si utilizamos los datos de Santander, el sistema tiene solución.
Si usamos los datos de Galicia el sistema no tiene solución.

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{2. Más ecuaciones que variables - La vida real}

Cuando consideramos un sistema con más ecuaciones que variables, en general \textbf{NO} tiene solución.

Aunque teóricamente exista solución, en la práctica siempre aparecen errores numéricos y no podemos determinar si un sistema tiene solución
(numéricamente es MUY difícil saber si un número es igual a 0 o no).

Solución: en vez de buscar una solución exacta del sistema de ecuaciones
$$ X c = y,$$
buscamos un vector $c$ que minimice el error, es decir, que haga pequeñas las coordenadas del vector de errores
$$ X c - y.$$

\end{frame}


%------------------------------------------------------------------

\begin{frame}
\frametitle{El milagro de los mínimos cuadrados}

Llegamos así al método de mínimos cuadrados. El vector $c$ que  minimiza la suma de los errores al cuadrado del sistema
$$ X c = y,$$
es solución del sistema lineal de ecuaciones
$$ X^T X c = X^T y.$$

Es un sistema cuadrado y en general tiene solución única.

El problema DIFICIL de minimizar los errores se transforma en el problema FÁCIL de resolver un sistema lineal de ecuaciones. \textbf{Este es el
milagro de los mínimos cuadrados.}

\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Resumen}

Tenemos dos modelos posibles y queremos elegir el más apropiado:
\begin{align*}
A) total &= c_1 \cdot YPF + c_2 \cdot Santander + c_3 \cdot Nvidia \\
B) total &= c_1 \cdot YPF + c_2 \cdot Galicia + c_3 \cdot Nvidia
\end{align*}

Seguimos los siguientes pasos:
\begin{enumerate}
\item Buscamos datos de la mayor cantidad posible de días.
\item Separamos el conjunto en dos: conjunto de entrenamiento ($80\%$ de los días) y conjunto de testeo ($20\%$ restante)
\item Calculamos $c_1, c_2, c_3$ para cada uno de los dos modelos utilizando mínimos cuadrados en el conjunto de entrenamiento.
\item Calculamos el error cuadrático medio de lás fórmulas resultantes aplicadas al conjunto de testeo.
\end{enumerate}

\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Modelo lineal multivariado}

El caso recién visto fue un ejemplo de juguete, donde existe una relación lineal entre las variables que tenemos que estimar.

En las aplicaciones reales, esa formula puede no existir (por ejemplo, si queremos estimar los gastos en tarjeta de crédito de una persona en
función del sueldo y la cantidad de hijos), pero el modelo lineal puede darnos una buena estimación.

En el modelo lineal suponemos que existe una relación del tipo
$$ X c = y.$$

Como esa relación en general no existe, buscamos un vector $c$ que haga que $X c$ se parezca lo más posible a $y$.

\end{frame}

%------------------------------------------------------------------

\begin{frame}
\frametitle{Ejercicio: modelos lineales}

Dadas una variable a predecir $y$ y variables explicativas $x_1, x_2, \dots$, ¿cuáles de los siguientes modelos son lineales? ¿Cuál es la matriz $X$
en cada caso?

\begin{enumerate}
\item $y = c_0 + c_1 x_1 + c_2 x_2$
\item $y = c_0 + c_1 x_1 + c_2 x_1^2$
\item $y = c_0 + c_1 x_1 + x_1^{c_2}$
\item $y = c_0 + c_1 x_1 + c_2 x_2 + c_3 x_1 x_2$
\item $y = c_0 + c_1 \sin(x_1) + c_2 \sin(x_2)$
\item $y = c_0 + c_1 \sin(c_2 + x_1)$
\item $y = c_0 + c_1 e^{x_1}$
\item $y = c_0 \cdot c_1 ^{x_1}$
\end{enumerate}

\pause Algunos de estos modelos se pueden linearizar, pero eso ya es otra historia...
\end{frame}
 %------------------------------------------------------------------

\begin{frame}
\frametitle{Ejemplo real: cálculo de calorías}

Vamos a repetir estos pasos en un caso real: calcular las calorías de un alimento en función de sus componentes, utilizando las herramientas de
Python para la construcción de modelos.
\begin{enumerate}
\item Construimos las matrices $X$ e $y$ utilizando \lstinline{Formulaic}.
\item Separamos las matrices en entrenamiento y testeo utilizando \lstinline{train_test_split}
\item Ajustamos el modelo utilizando \lstinline{linear_model.fit()}.
\item Calculamos el error en los datos de testeo utilizando \lstinline{linear_model.predict()}.
\end{enumerate}

\end{frame}




\end{document}
